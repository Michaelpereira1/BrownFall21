---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.10.3
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

```{code-cell} ipython3
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from sklearn import datasets
from sklearn import cluster
from sklearn import svm
from sklearn import tree
# import the whole model selection module
from sklearn import model_selection
sns.set_theme(palette='colorblind')

# load and split the data
iris_X, iris_y = datasets.load_iris(return_X_y=True)
iris_X_train, iris_X_test, iris_y_train, iris_y_test = model_selection.train_test_split(
  iris_X,iris_y, test_size =.2)


# create dt, set param grid & create optimizer
dt = tree.DecisionTreeClassifier()

params_dt = {'criterion':['gini','entropy'],
       'max_depth':[2,3,4,5,6],
    'min_samples_leaf':list(range(2,20,2))}

dt_opt = model_selection.GridSearchCV(dt,params_dt,cv=10)


# fit the model and optimize
dt_opt.fit(iris_X_train,iris_y_train)

# store the resutl sin a dataframe
dt_df = pd.DataFrame(dt_opt.cv_results_)


# create svm, its parameter grid and optimizer
svm_clf = svm.SVC()
param_grid = {'kernel':['linear','rbf'], 'C':[.5, .75,1,2,5,7, 10]}
svm_opt = model_selection.GridSearchCV(svm_clf,param_grid,cv=10)

# fit the model and put the CV results in a dataframe
svm_opt.fit(iris_X_train,iris_y_train)
sv_df = pd.DataFrame(svm_opt.cv_results_)
```

```{code-cell} ipython3
svm_opt.best_score_, dt_opt.best_score_
```

```{code-cell} ipython3
svm_opt.best_estimator_.score(iris_X_test,iris_y_test)
```

```{code-cell} ipython3
dt_opt.best_estimator_.score(iris_X_test,iris_y_test)
```

```{code-cell} ipython3
sv_df.head(2)
```

```{code-cell} ipython3
sv_df['mean_test_score'].mean()
```

```{code-cell} ipython3
sv_df['mean_test_score'].describe()
```

```{code-cell} ipython3
dt_df['mean_test_score'].describe()
```

```{code-cell} ipython3
def classification_confint(acc, n):
    '''
    Compute the 95% confidence interval for a classification problem.
    acc -- classification accuracy
    n  -- number of observations used to compute the accuracy
    Returns a tuple (lb,ub)
    '''
    interval = 1.96*np.sqrt(acc*(1-acc)/n)
    lb = max(0, acc - interval)
    ub = min(1.0, acc + interval)
    return (lb,ub)
```

```{code-cell} ipython3
svm_opt.best_score_, dt_opt.best_score_
```

```{code-cell} ipython3
len(iris_X_train)*.1
```

```{code-cell} ipython3
classification_confint( dt_opt.best_score_,12)
```

```{code-cell} ipython3
len(iris_y_test)
```

```{code-cell} ipython3
classification_confint(dt_opt.best_estimator_.score(iris_X_test,iris_y_test),len(iris_y_test))
```

```{code-cell} ipython3
classification_confint(.95,12)
```

```{code-cell} ipython3
classification_confint(.95,30)
```

```{code-cell} ipython3

```
